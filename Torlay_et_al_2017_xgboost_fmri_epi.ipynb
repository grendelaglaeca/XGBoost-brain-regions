{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torlay et al 2017 xgboost fmri epi",
      "provenance": [],
      "authorship_tag": "ABX9TyO9NNrlVlZ+0r4Vmx1Rhrhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grendelaglaeca/XGBoost-brain-regions/blob/main/Torlay_et_al_2017_xgboost_fmri_epi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supplementary Material for the manuscript:**\n",
        "\n",
        "**“Machine Learning-XGBoost Analysis of language networks to classify patients with epilepsy”**"
      ],
      "metadata": {
        "id": "kT0M9yDb1YV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to achieve the Machine Learning analysis, we constructed this Python script code with the help of Scikit-Learn 0.18 python libraries (http://scikit-learn.org).\n",
        "We wrote it with Pycharm 2016.2.3 (https://www.jetbrains.com/pycharm/) and we used Anaconda (https://www.continuum.io/) to get an update distribution of Python libraries.\n"
      ],
      "metadata": {
        "id": "x7zTNLc71zNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "=========================================\n",
        "Nested cross-validation\n",
        "=========================================\n",
        ".. topic:: References:\n",
        "    .. [1] `Cawley, G.C.; Talbot, N.L.C. On over-fitting in model selection and\n",
        "     subsequent selection bias in performance evaluation.\n",
        "     J. Mach. Learn. Res 2010,11, 2079-2107.\n",
        "     <http://jmlr.csail.mit.edu/papers/volume11/cawley10a/cawley10a.pdf>`_\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QSIKry5t1ynL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries and ML modules"
      ],
      "metadata": {
        "id": "4Xq5z7bS2QZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFyU1dE00wVR",
        "outputId": "e16b6003-75f9-4e27-a5cf-63b6a9b2fb9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatically created module for IPython interactive environment\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "\n",
        "print(__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start time clock\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "# Load data from CSV file\n",
        "donnees = pd.read_csv(./data.csv',sep=';')\n",
        "\n",
        "print(donnees.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "dd7bJBGB2DkA",
        "outputId": "97eeb4bb-8d59-4bfe-8e93-5ffae9604eb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-60209bf76567>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    donnees = pd.read_csv(./data.csv',sep=';')\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.array(donnees)\n",
        "\n",
        "# Separate the data from the target attributes\n",
        "X = dataset[:, 1:21]\n",
        "y = dataset[:, 0]\n",
        "\n",
        "# Data balance\n",
        "print(np.count_nonzero(y == 1))\n",
        "print(np.count_nonzero(y == 0))"
      ],
      "metadata": {
        "id": "q1CwHlnu2Kp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are the brain regions (based on Glasser parcellation) that activated in response to each task (semantic decision, phonological decision):"
      ],
      "metadata": {
        "id": "6K1lvsh53WGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinations of features to study\n",
        "\n",
        "# Semantic Bilateral\n",
        "S1 = [16, 18]\n",
        "S2 = [8, 12, 10, 14]\n",
        "S3 = [8, 12, 16, 10, 14, 18]\n",
        "S4 = [0, 2]\n",
        "S5 = [4, 6]\n",
        "S6 = [0, 4, 2, 6]\n",
        "S7 = [0, 16, 2, 18]\n",
        "S8 = [4, 16, 6, 18]\n",
        "S9 = [0, 4, 16, 2, 6, 18]\n",
        "S10 = [0, 8, 12, 2, 10, 14]\n",
        "S11 = [4, 8, 12, 6, 10, 14]\n",
        "S12 = [0, 4, 8, 12, 2, 6, 10, 14]\n",
        "S13 = [0, 8, 12, 16, 2, 10, 14, 18]\n",
        "S14 = [4, 8, 12, 16, 6, 10, 14, 18]\n",
        "S15 = [0, 4, 8, 12, 16, 2, 6, 10, 14, 18]\n",
        "\n",
        "# Phonologic Bilateral\n",
        "P1 = [17, 19]\n",
        "P2 = [9, 12, 11, 15]\n",
        "P3 = [9, 12, 17, 11, 15, 19]\n",
        "P4 = [1, 3]\n",
        "P5 = [5, 7]\n",
        "P6 = [1, 5, 3, 7]\n",
        "P7 = [1, 17, 3, 19]\n",
        "P8 = [5, 17, 7, 19]\n",
        "P9 = [1, 5, 17, 3, 7, 19]\n",
        "P10 = [1, 9, 12, 3, 11, 15]\n",
        "P11 = [5, 9, 12, 7, 11, 15]\n",
        "P12 = [1, 5, 9, 12, 3, 7, 11, 15]\n",
        "P13 = [1, 9, 12, 17, 3, 11, 15, 19]\n",
        "P14 = [5, 9, 12, 17, 7, 11, 15, 19]\n",
        "P15 = [1, 5, 9, 12, 17, 3, 7, 11, 15, 19]\n",
        "\n",
        "# SEM+PHONO Bilateral\n",
        "M1 = [16, 18, 17, 19]\n",
        "M2 = [8, 12, 10, 14, 9, 13, 11, 15]\n",
        "M3 = [8, 12, 16, 10, 14, 18, 9, 13, 17, 11, 15, 19]\n",
        "M4 = [0, 2, 1, 3]\n",
        "M5 = [4, 6, 5, 7]\n",
        "M6 = [0, 4, 2, 6, 1, 5, 3, 7]\n",
        "M7 = [0, 16, 2, 18, 1, 17, 3, 19]\n",
        "M8 = [4, 16, 6, 18, 5, 17, 7, 19]\n",
        "M9 = [0, 4, 16, 2, 6, 18, 1, 5, 17, 3, 7, 19]\n",
        "M10 = [0, 8, 12, 2, 10, 14, 1, 9, 13, 3, 11, 15]\n",
        "M11 = [4, 8, 12, 6, 10, 14, 5, 9, 13, 7, 11, 15]\n",
        "M12 = [0, 4, 8, 12, 2, 6, 10, 14, 1, 5, 9, 13, 3, 7, 11, 15]\n",
        "M13 = [0, 8, 12, 16, 2, 10, 14, 18, 1, 9, 13, 17, 3, 11, 15, 19]\n",
        "M14 = [4, 8, 12, 16, 6, 10, 14, 18, 5, 9, 13, 17, 7, 11, 15, 19]\n",
        "M15 = [0, 4, 8, 12, 16, 2, 6, 10, 14, 18, 1, 5, 9, 13, 17, 3, 7, 11, 15, 19]\n",
        "\n",
        "# Semantic Left Hemisphere\n",
        "I1 = [16]\n",
        "I2 = [8, 12]\n",
        "I3 = [8, 12, 16]\n",
        "I4 = [0]\n",
        "I5 = [4]\n",
        "I6 = [0, 4]\n",
        "I7 = [0, 16]\n",
        "I8 = [4, 16]\n",
        "I9 = [0, 4, 16]\n",
        "I10 = [0, 8, 12]\n",
        "I11 = [4, 8, 12]\n",
        "I12 = [0, 4, 8, 12]\n",
        "I13 = [0, 8, 12, 16]\n",
        "I14 = [4, 8, 12, 16]\n",
        "I15 = [0, 4, 8, 12, 16]\n",
        "\n",
        "# Phonologic Left Hemisphere\n",
        "J1 = [17]\n",
        "J2 = [9, 13]\n",
        "J3 = [9, 13, 17]\n",
        "J4 = [1]\n",
        "J5 = [5]\n",
        "J6 = [1, 5]\n",
        "J7 = [1, 17]\n",
        "J8 = [5, 17]\n",
        "J9 = [1, 5, 17]\n",
        "J10 = [1, 9, 13]\n",
        "J11 = [5, 9, 13]\n",
        "J12 = [1, 5, 9, 13]\n",
        "J13 = [1, 9, 13, 17]\n",
        "J14 = [5, 9, 13, 17]\n",
        "J15 = [1, 5, 9, 13, 17]\n",
        "\n",
        "# Semantic Right Hemisphere\n",
        "K1 = [18]\n",
        "K2 = [10, 14]\n",
        "K3 = [10, 14, 18]\n",
        "K4 = [2]\n",
        "K5 = [6]\n",
        "K6 = [2, 6]\n",
        "K7 = [2, 18]\n",
        "K8 = [6, 18]\n",
        "K9 = [2, 6, 18]\n",
        "K10 = [2, 10, 14]\n",
        "K11 = [6, 10, 14]\n",
        "K12 = [2, 6, 10, 14]\n",
        "K13 = [2, 10, 14, 18]\n",
        "K14 = [6, 10, 14, 18]\n",
        "K15 = [2, 6, 10, 14, 18]\n",
        "\n",
        "# Phonologic Right Hemisphere\n",
        "\n",
        "L1 = [19]\n",
        "L2 = [11, 15]\n",
        "L3 = [11, 15, 19]\n",
        "L4 = [3]\n",
        "L5 = [7]\n",
        "L6 = [3, 7]\n",
        "L7 = [3, 19]\n",
        "L8 = [7, 19]\n",
        "L9 = [3, 7, 19]\n",
        "L10 = [3, 11, 15]\n",
        "L11 = [7, 11, 15]\n",
        "L12 = [3, 7, 11, 15]\n",
        "L13 = [3, 11, 15, 19]\n",
        "L14 = [7, 11, 15, 19]\n",
        "L15 = [3, 7, 11, 15, 19]\n",
        "\n",
        "# SEM+PHONO Left Hemisphere\n",
        "N1 = [16, 17]\n",
        "N2 = [8, 12, 9, 13]\n",
        "N3 = [8, 12, 16, 9, 13, 17]\n",
        "N4 = [0, 1]\n",
        "N5 = [4, 5]\n",
        "N6 = [0, 4, 1, 5]\n",
        "N7 = [0, 16, 1, 17]\n",
        "N8 = [4, 16, 5, 17]\n",
        "N9 = [0, 4, 16, 1, 5, 17]\n",
        "N10 = [0, 8, 12, 5, 9, 13]\n",
        "N11 = [4, 8, 12, 5, 9, 13]\n",
        "N12 = [0, 4, 8, 12, 1, 5, 9, 13]\n",
        "N13 = [0, 8, 12, 16, 1, 9, 13, 17]\n",
        "N14 = [4, 8, 12, 16, 5, 9, 13, 17]\n",
        "N15 = [0, 4, 8, 12, 16, 1, 5, 9, 13, 17]\n",
        "\n",
        "# SEM+PHONO Right Hemisphere\n",
        "\n",
        "R1 = [18, 19]\n",
        "R2 = [10, 14, 11, 15]\n",
        "R3 = [10, 14, 18, 11, 15, 19]\n",
        "R4 = [2, 3]\n",
        "R5 = [6, 7]\n",
        "R6 = [2, 6, 3, 7]\n",
        "R7 = [2, 18, 3, 19]\n",
        "R8 = [6, 18, 7, 19]\n",
        "R9 = [2, 6, 18, 3, 7, 19]\n",
        "R10 = [2, 10, 14, 7, 11, 15]\n",
        "R11 = [6, 10, 14, 7, 11, 15]\n",
        "R12 = [2, 6, 10, 14, 3, 7, 11, 15]\n",
        "R13 = [2, 10, 14, 18, 3, 11, 15, 19]\n",
        "R14 = [6, 10, 14, 18, 7, 11, 15, 19]\n",
        "R15 = [2, 6, 10, 14, 18, 3, 7, 11, 15, 19]\n"
      ],
      "metadata": {
        "id": "h4FzFeZ1260P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are subsets of features that the authors compiled based on existing literature, such as brain regions that are connected structurally (anatomically) or functionally (e.g. constituting the semantic network). This was done to reduce the number of combinations and to increase the interpretability of the results."
      ],
      "metadata": {
        "id": "19EEjdIP4EhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Subsets\n",
        "subsets_S = [S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11, S12, S13, S14, S15]\n",
        "subsets_P = [P1, P2, P3, P4, P5, P6, P7, P8, P9, P10, P11, P12, P13, P14, P15]\n",
        "subsets_M = [M1, M2, M3, M4, M5, M6, M7, M8, M9, M10, M11, M12, M13, M14, M15]\n",
        "subsets_I = [I1, I2, I3, I4, I5, I6, I7, I8, I9, I10, I11, I12, I13, I14, I15]\n",
        "subsets_J = [J1, J2, J3, J4, J5, J6, J7, J8, J9, J10, J11, J12, J13, J14, J15]\n",
        "subsets_K = [K1, K2, K3, K4, K5, K6, K7, K8, K9, K10, K11, K12, K13, K14, K15]\n",
        "subsets_L = [L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, L11, L12, L13, L14, L15]\n",
        "subsets_L = [L1, L2, L3, L4, L5, L6, L7, L8, L9, L10, L11, L12, L13, L14, L15]\n",
        "subsets_N = [N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, N11, N12, N13, N14, N15]\n",
        "subsets_R = [R1, R2, R3, R4, R5, R6, R7, R8, R9, R10, R11, R12, R13, R14, R15]\n",
        "\n",
        "\n",
        "subsets_sum = subsets_S + subsets_P + subsets_M + subsets_I + subsets_J + subsets_K + subsets_L + subsets_N + subsets_R\n"
      ],
      "metadata": {
        "id": "L_lDVdRG36PK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}